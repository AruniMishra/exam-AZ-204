
# Azure

- [Azure](#azure)
  - [App Service Environment](#app-service-environment)
  - [Vnet](#vnet)
  - [Azure Function](#azure-function)
    - [Durable function](#durable-function)
  - [Storage account](#storage-account)
  - [PowerShell](#powershell)
  - [Azure Cosmos DB](#azure-cosmos-db)
  - [Virtual Machine](#virtual-machine)
  - [Azure Blob storage](#azure-blob-storage)
  - [Azure Event Grid](#azure-event-grid)
  - [Azure Event Hub](#azure-event-hub)
  - [Azure Active Directory](#azure-active-directory)
    - [identity-protection](#identity-protection)
  - [Key Vault](#key-vault)
  - [api-management](#api-management)
  - [Azure Service Bus](#azure-service-bus)
    - [Azure service Bus Topics](#azure-service-bus-topics)
  - [Azure Storage Queue](#azure-storage-queue)
  - [Kubernetes](#kubernetes)
  - [Azure Resource Manager](#azure-resource-manager)
  - [Container registries](#container-registries)
  - [Rest](#rest)
  - [Azure Monitor](#azure-monitor)
  - [Azure front door](#azure-front-door)
  - [CDN](#cdn)
  - [pattern](#pattern)
  - [Notification Hub](#notification-hub)
  - [WebJob](#webjob)
  - [Logic apps](#logic-apps)
  - [Comparison](#comparison)

## App Service Environment

- In the Isolated tier, the App Service Environment defines the number of isolated workers that run your apps, and each worker is charged. In addition, there's a flat Stamp Fee for the running the App Service Environment itself. Isolated: This tier runs dedicated Azure VMs on dedicated Azure Virtual Networks. It provides network isolation on top of compute isolation to your apps. It provides the maximum scale-out capabilities.

- WebJobs is a feature of Azure App Service that enables you to run a program or script in the same instance as a web app, API app, or mobile app. There is no additional cost to use WebJobs.  
  You can use the Azure WebJobs SDK with WebJobs to simplify many programming tasks. WebJobs is not yet supported for App Service on Linux.

- Specify custom warm-up
  - Some apps might require custom warm-up actions before the swap. The **applicationInitialization** configuration element in web.config lets you specify custom initialization actions. The swap operation waits for this custom warm-up to finish before swapping with the target slot. Here's a sample web.config fragment.
  
    ```xml
    <system.webServer>
        <applicationInitialization>
            <add initializationPage="/" hostName="[app hostname]" />
            <add initializationPage="/Home/About" hostName="[app hostname]" />
        </applicationInitialization>
    </system.webServer>
    ```

- Warm up : You can also customize the warm-up behavior with one or both of the following app settings:
  - **WEBSITE_SWAP_WARMUP_PING_PATH**: The path to ping to warm up your site. Add this app setting by specifying a custom path that begins with a slash as the value. An example is /statuscheck. The default value is /.
  - **WEBSITE_SWAP_WARMUP_PING_STATUSES**: Valid HTTP response codes for the warm-up operation. Add this app setting with a comma-separated list of HTTP codes. An example is 200,202 . If the returned status code isn't in the list, the warmup and swap operations are stopped. By default, all response codes are valid.
  - **WEBSITE_WARMUP_PATH**: A relative path on the site that should be pinged whenever the site restarts (not only during slot swaps). Example values include /statuscheck or the root path, /.

  - Auto-Swap is only available on Windows-based App Services
  - Requires at least a standard plan.

- "use multiple containers in the same container group" this not is possible in windows.Solution is: Linux

  ```code
  -sku B1 --is-linux
  -deployment-container-image-name images.azurecr.io/website:v1.0.0
  -container set --docker-registry-server-url https://images.azurecr.io -u admin -p admin
  ```

- Within the same resource group, you can't mix Windows and Linux apps in the same region. However, all resource groups created on or after January 21, 2021 do support this scenario. For resource groups created before January 21, 2021, the ability to add mixed platform deployments will be rolled out across Azure regions (including National cloud regions) soon.

- Always On enables waking up on HTTPTrigger, but does not prevent the exceeding the max time out time of 230 seconds.

- The Standard tier supports auto-scaling.

- If **WEBSITES_ENABLE_APP_SERVICE_STORAGE** setting is unspecified or set to false, the /home/ directory will not be shared across scale instances, and files written will not persist across restarts. Explicitly setting **WEBSITES_ENABLE_APP_SERVICE_STORAGE** to true will enable the mount. Once this is set to true, if you wish to disable the mount, you need to explicitly set **WEBSITES_ENABLE_APP_SERVICE_STORAGE** to false.

- **UseAzureAppConfiguration**: It enables your application to use the App Configuration middleware to handle the configuration updates for you automatically. No resart is needed.

- Consumption plan can take up to several minutes to trigger the function.

## Vnet

- Key Vault references currently only support system-assigned managed identities. User-assigned

## Azure Function

- Triggers and bindings
  
  - Use an App Service plan. Configure the Function App to use an Azure Blob Storage trigger.
  Consumption plan can cause a 10-min delay in processing new blobs if a function app has gone idle. To avoid this latency, you can switch to an App Service plan with Always On enabled. [Azure Blob storage trigger for Azure Functions](https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger?tabs=csharp)

  - If you require faster or more reliable blob processing, consider creating a queue message when you create the blob. Then use a **queue trigger** instead of a blob trigger to process the blob. Another option is to use **Event Grid**;
  
- When you create an Azure Functions trigger for Azure Cosmos DB, you select the container to connect, and the Azure Function gets triggered whenever there is a change in the container. Because Azure Functions uses the change feed processor behind the scenes, it automatically parallelizes change processing across your container's partitions.

- Binding extension
  - Starting with Azure Functions version 2.x, the functions runtime only includes HTTP and timer triggers by default. Other triggers and bindings are available as separate packages.

### Durable function

- Durable Functions is an extension of Azure Functions that lets you write stateful functions in a serverless compute environment. The extension lets you define stateful workflows by writing **orchestrator functions** and stateful entities by writing **entity functions** using the Azure Functions programming model. Behind the scenes, the extension manages state, checkpoints, and restarts for you, allowing you to focus on your business logic.

  - Pattern #1: Function chaining
    - In the function chaining pattern, a sequence of functions executes in a specific order. In this pattern, the output of one function is applied to the input of another function.
  - Pattern #2: Fan out/fan in
    - In the fan out/fan in pattern, you execute multiple functions in parallel and then wait for all functions to finish.
  - Pattern #3: Async HTTP APIs
    - The async HTTP API pattern addresses the problem of coordinating the state of long-running operations with external clients. A common way to implement this pattern is by having an HTTP endpoint trigger the long-running action. Then, redirect the client to a status endpoint that the client polls to learn when the operation is finished.

## Storage account

- the change feed provides transaction logs of all the changes that occur to the blobs and the blob metadata in your storage account. The change feed provides ordered, guaranteed, a durable, immutable, read-only log of these changes. You can process these logs asynchronously, incrementally or in-full. If your application has to react to events much quicker than this, consider using Blob Storage events instead. Blob Storage Events provides real-time one-time events which enable your Azure Functions or applications to quickly react to changes that occur to a blob.

- The table api works for Azure Storage account and Cosmos DB.

- Azure Storage Client library for .NET
  - leaseTime is a TimeSpan representing the span of time for which to acquire the lease, which will be rounded down to seconds. If null, an infinite lease will be acquired. If not null, this must be 15 to 60 seconds
  - The BreakLeaseAsync method initiates an asynchronous operation that breaks the current lease on this container.

- Only the hot and cool access tiers can be set at the account level. The archive access tier can only be set at the blob level.

- Archive access
  - Standard priority - 15 hours
  - High priority - 1 hour for objects under 10 GB

- The Azcopy tool can be used to copy data from one storage account to another. You can use the tool within automation scripts to ensure the data can be copied automatically.

- You can't convert an existing standard performance storage account to a block blob storage account with premium performance. To migrate to a premium performance storage account, you must create a premium block blob account, and migrate the data to the new account.

- BlockBlobStorage accounts provide low, consistent latency and higher transaction rates.

- TLSMA
  - If you are using ASP.NET and configure your app to use client certificate authentication, the certificate will be available through the **HttpRequest.ClientCertificate** property.
  - For other application stacks, the client cert will be available in your app through a base64 encoded value in the "**X-ARR-ClientCert**" request header. Your application can create a certificate from this value and then use it for authentication and authorization purposes in your application.

## PowerShell

- Dockerfile sequence:

  ```code
  FROM node:latest
  WORKDIR /usr/src/app
  COPY package.json .
  RUN npm install
  COPY . ./
  EXPOSE 3000
  CMD [ “npm”, “start” ]
  ```
  
  FWCREC

## Azure Cosmos DB

- Azure Cosmos DB offers five well-defined levels. From strongest to weakest, [the levels are](https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels): 'StBoSeConE'
  - Strong
    - Strong consistency offers a linearizability guarantee. Linearizability refers to serving requests concurrently. The reads are guaranteed to return the most recent committed version of an item. A client never sees an uncommitted or partial write. Users are always guaranteed to read the latest committed write.
  - Bounded staleness
    - In bounded staleness consistency, the reads are guaranteed to honor the consistent-prefix guarantee. The reads might lag behind writes by at most "K" versions (that is, "updates") of an item or by "T" time interval, whichever is reached first.
    - For a single region account, the minimum value of K and T is 10 write operations or 5 seconds. For multi-region accounts the minimum value of K and T is 100,000 write operations or 300 seconds.
  - Session
    - In session consistency, within a single client session reads are guaranteed to honor the consistent-prefix, monotonic reads, monotonic writes, read-your-writes, and write-follows-reads guarantees. This assumes a single "writer" session or sharing the session token for multiple writers.
  - Consistent prefix
    - In consistent prefix option, updates that are returned contain some prefix of all the updates, with no gaps. Consistent prefix consistency level guarantees that reads never see out-of-order writes.
    - If writes were performed in the order A, B, C, then a client sees either A, A,B, or A,B,C, but never out-of-order permutations like A,C or B,A,C. Consistent Prefix provides write latencies, availability, and read throughput comparable to that of eventual consistency, but also provides the order guarantees that suit the needs of scenarios where order is important.
  - Eventual
    - In eventual consistency, there's no ordering guarantee for reads. In the absence of any further writes, the replicas eventually converge.

- For multi-region Cosmos accounts that are configured with a single-write region, enable automatic-failover by using Azure CLI or Azure portal. After you enable automatic failover, whenever there is a regional disaster, Cosmos DB will automatically failover your account.

- locations param
  - --locations : Add a location to the Cosmos DB database account.
    Usage: --locations KEY=VALUE [KEY=VALUE ...]
    Required Keys: regionName, failoverPriority
    Optional Key: isZoneRedundant
    Default: single region account in the location of the specified resource group.
    Failover priority values are 0 for write regions and greater than 0 for read regions. A
    failover priority value must be unique and less than the total number of regions.
    Multiple locations can be specified by using more than one `--locations` argument.

- You can form a partition key by concatenating multiple property values into a single artificial partitionKey property. These keys are referred to as synthetic keys.
Another possible strategy to distribute the workload more evenly is to append a random number at the end of the partition key value. When you distribute items in this way, you can perform parallel write operations across partitions.

- In order to be an in-partition query, the query must have an ~equality filter~ that includes the partition key. A query that has a ~range filter~ on the partition key and won't be scoped to a single physical partition, hence it is not in-partition query.

- Throughput:
  - You set the highest, or maximum RU/s Tmax you don't want the system to exceed. The system automatically scales the throughput T such that 0.1* Tmax <= T <= Tmax, for example we have autoscaleMaxThroughput = 5000, so the minimum throughput for the container is 500 R/Us.

- in order to use **order by** on multiple properties of item, we need to add composite key.  

- New records are inserted with TableOperation.insert. Old records are not updated. To update old records TableOperation.insertOrReplace should be used instead.

- change-feed-processor  

  - The monitored container -
    The monitored container has the data from which the change feed is generated. Any inserts and updates to the monitored container are reflected in the change feed of the container.

  - The lease container -
    The lease container acts as a state storage and coordinates processing the change feed across multiple workers. The lease container can be stored in the same account as the monitored container or in a separate account.

  - The host: A host is an application instance that uses the change feed processor to listen for changes. Multiple instances with the same lease configuration can run in parallel, but each instance should have a different instance name.

  - The delegate -
    The delegate is the code that defines what you, the developer, want to do with each batch of changes that the change feed processor reads.

## Virtual Machine

- Run scripts in your Windows
  
  - Custom Script Extension
    - The Custom Script Extension is primarily used for post deployment configuration and software installation.

  - Run command
    - The Run Command feature enables virtual machine and application management and troubleshooting using scripts, and is available even when the machine is not reachable, for example if the guest firewall doesn't have the RDP or SSH port open.

- You can store images in Azure Blob Storage.

- In order to grant VM access to ARM you need to:
  - assign VM user/system managed identity
  - configure permission to ARM for that identity
  - and then you can access token by Invoke-WebRequest cmdlet and use it to authenticate in ARM.

## Azure Blob storage

- Standard priority: The rehydration request will be processed in the order it was received and may take up to 15 hours.
- High priority: The rehydration request will be prioritized over Standard requests and may finish in under 1 hour for objects under ten GB in size.

## Azure Event Grid

- Event Grid doesn't guarantee order for event delivery, so subscribers may receive them out of order.

- When creating an event subscription, you have three options for filtering:
  - Event types
  - Subject begins with or ends with
  - Advanced fields and operators

## Azure Event Hub

- we don't bothered about the sequencing of messages

- Capturing and Partitioning, these are features of event hub and are note available in event grid

- **Azure Event Hubs Capture** enables you to automatically capture the streaming data in Event Hubs in an **Azure Blob storage** or **Azure Data Lake Storage Gen 1 or Gen 2** account of your choice, with the added flexibility of specifying a time or size interval.

- The recommendation is to have one receiver per partition
  - You can have upto 5 concurrent readers per partition per consumer group
  - But you have to be careful not to dupliate the process of reading the same messages.

## Azure Active Directory

- MFA Enabled by **conditional access policy**. Multi-Factor Authentication comes as part of the following offerings:
  - Azure Active Directory Premium licenses - Full featured use of Azure Multi-Factor Authentication Service (Cloud) or Azure Multi-Factor Authentication Server (On-premises).
  - Multi-Factor Authentication for Office 365.
  - Azure Active Directory Global Administrators.

- To configure Manifest to include Group Claims in Auth Token
  1. Go to Azure Active Directory to configure the Manifest. Click on Azure Active Directory, and go to App registrations to find your application:
  2. Click on your application (or search for it if you have a lot of apps) and edit the Manifest by clicking on it.
  3. Locate the ג€groupMembershipClaimsג€ setting. Set its value to either ג€SecurityGroupג€ or ג€Allג€. To help you decide which:
      SecurityGroup - groups claim will contain the identifiers of all security groups of which the user is a member.
      All - groups claim will contain the identifiers of all security groups and all distribution lists of which the user is a member

- Permission:
  - Application Permissions: Your application needs to access the web API directly as itself (no user context). This type of permission requires administrator consent and is also not available for native client applications.
  - Delegation Permissions: Your application needs to access the web API as the signed-in user, but with access limited by the selected permission. This type of permission can be granted by a user unless the permission is configured as requiring administrator consent.

- Azure Active Directory Managed Service Identity (MSI) gives your code an automatically managed identity for authenticating to Azure services, so that you can keep credentials out of your code.
  - Note: Use the authentication-managed-identity policy to authenticate with a backend service using the managed identity. This policy essentially uses the managed identity to obtain an access token from Azure Active Directory for accessing the specified resource. After successfully obtaining the token, the policy will set the value of the token in the Authorization header using the Bearer scheme.

  - There are two types of managed identities:

    - System-assigned Some Azure services allow you to enable a managed identity directly on a service instance. When you enable a system-assigned managed identity an identity is created in Azure AD that is tied to the lifecycle of that service instance. So when the resource is deleted, Azure automatically deletes the identity for you. By design, only that Azure resource can use this identity to request tokens from Azure AD.

    - User-assigned You may also create a managed identity as a standalone Azure resource. You can create a user-assigned managed identity and assign it to one or more instances of an Azure service. In the case of user-assigned managed identities, the identity is managed separately from the resources that use it.

- Azure Active Directory app manifest:
  - oauth2Permissions can only accept collections/array value
  - oauth2AllowImplicitFlow takes boolean value- if we want the application to fetch the required tokens, we would need to allow Implicit Flow

- A (X.509) certificate cannnot be used to authenticate. Instead run the Invoke-RestMethod or **Invoke-WebRequest** cmdlet to make a request to the local managed identity for Azure resources endpoint to get an access token for Azure Resource Manager.

- Role-based access control is used for authorization and not authentication.

### identity-protection

- Risk remediation:
  - Organizations can choose to block access when risk is detected. Blocking sometimes stops legitimate users from doing what they need to. A better solution is to allow self-remediation using Azure AD Multi-Factor Authentication (MFA) and self-service password reset (SSPR).

- Authenticate the app
  - You need "ID Token Claims" for authorisation.  
    You need to validate "ID Token signature" as a part of authentication.  
    &  
    URI has tenant ID in it.

## Key Vault

- Key Vault references will use the app's system assigned identity by default, but you can specify a user-assigned identity.

- A Key Vault customer would like to securely transfer a key from their on-premises HSM outside Azure, into the HSM backing Azure Key Vault. The process of importing a key generated outside Key Vault is generally referred to as Bring Your Own Key (BYOK).

  The following are the requirements:  
  - The key to be transferred never exists outside an HSM in plain text form.
  - Outside an HSM, the key to be transferred is always protected by a key held in the Azure Key Vault HSM

  - User steps  
    To perform a key transfer, a user performs following steps:
      1. Generate KEK.
      2. Retrieve the public key of the KEK.
      3. Using HSM vendor provided BYOK tool - Import the KEK into the target HSM and exports the Target Key protected by the KEK.
      4. Import the protected Target Key to Azure Key Vault.

      Customers use the BYOK tool and documentation provided by HSM vendor to complete Steps 3. It produces a Key Transfer Blob (a ".byok" file).

## api-management

- Add the validate-jwt policy to validate the OAuth token for every incoming request(validate-jwt for Open ID, API, secure authentication)

- Send request context information to the backend service > Inbound
  - e.g. Forward the user id associated with the subscription key in the request as well as the region where the proxy processing the request is hosted.

- cache-store-value is not as same as cache-value.

  - [cache-store is Outbound](https://docs.microsoft.com/en-us/azure/api-management/api-management-caching-policies#example)

  - [cache-store-value is Inbound](https://docs.microsoft.com/en-us/azure/api-management/api-management-sample-cache-by-key#fragment-caching)

- Authentication policies(API-M)
  - Authenticate with Basic - Authenticate with a backend service using Basic authentication.
  - Authenticate with client certificate - Authenticate with a backend service using client certificates.
  - Authenticate with managed identity - Authenticate with the managed identity for the API Management service.

- If backend is accepts HTTP(S), Then Basic AUTH or Certificate will work.

- Consumption Pricing Tier of API Management does not support Built-in Cache
  - cache-lookup:

    > Attribute caching-type:
    - internal to use the built-in API Management cache,
    - external to use the external cache as described in [Use an external Azure Cache for Redis in Azure API Management](https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-cache-external),
    - prefer-external to use external cache if configured or internal cache otherwise.
    ---
    > Attribute downstream-caching-type:
    - none - downstream caching is not allowed.
    - private - downstream private caching is allowed.
    - public - private and shared downstream caching is allowed.

- Policies in Azure API Management are divided into inbound, backend, outbound, and on-error.
  - If there is no on-error section, callers will receive 400 or 500 HTTP response messages if an error condition occurs.
  - When an error occurs and control jumps to the on-error policy section, the error is stored in context.LastError property, which can be accessed by policies in the on-error section.

- Define Policies:
  - Access restriction policies:
    > Validate JWT
    - The validate-jwt policy enforces existence and validity of a JSON web token (JWT) extracted from either a specified HTTP Header or a specified query parameter.
    - This policy can be used in the following policy sections and scopes.
      - **Policy sections:** inbound
      - **Policy scopes:** all scopes

## Azure Service Bus

- [Message handling](https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messages-payloads)
  - CorrelationId: Enables an application to specify a context for the message for the purposes of correlation; for example, reflecting the MessageId of a message that is being replied to.
  - ReplyToSessionId: This value augments the ReplyTo information and specifies which SessionId should be set for the reply when sent to the reply entity.

- FIFO is supported by Service bus, for this you need to enable sessions for the queue.

- Azure Event Hub is for telemetry and distributed data broadcasting, while Azure Service Bus can be used for order processing and financial transactions. **Event Hub** is for collecting millions of events per second for processing. **Notification Hub** is for sending notifications to millions of devices. Notification hub is for pushing the data, to a mobile device, not for collecting the data.

### Azure service Bus Topics

- Filters (on subscription)
  - SQL Filter  : SQL like condition for evaluation. This can be done against the sytem(properties must be prefixed with sys) or user defined properties.
  - Boolean Filter  : TrueFilter or FalseFilter.
  - Correlation Filter  : Conditions can be used to match against the user's or system properties. Process faster than SQl Filters. A match exists when an arriving message's value for a property is equal to the value specified in the correlation filter (a CorrelationFilter can only match properties by equality (=))

## Azure Storage Queue

- You can peek at the message in the front of a queue without removing it from the queue by calling the PeekMessage method.

- The QueueDescription.LockDuration property gets or sets the duration of a peek lock; that is, the amount of time that the message is locked for other receivers.
The maximum value for LockDuration is 5 minutes; the default value is 1 minute.

- Queue Storage **does not** provide transactional support

- GetMessageAsync: Gets a message from the queue using the default request options. This operation marks the retrieved message as invisible in the queue for the default visibility timeout period. Only marks the message is invisible but does not delete.

- Azure.Storage.Queues.QueueClient supports "At-Most-Once" deliver mode("message must NOT persist after being processed").

- When changes are infrequent, but your scenario requires immediate responsiveness, event-based architecture can be especially efficient. Create an Event Grid topic that uses the Start-AzureStorageBlobCopy cmdlet.

## Kubernetes

- Deployment
To deploy Azure Functions to Kubernetes use the func kubernetes deploy command has several attributes that directly control how our app scales, once it is deployed to Kubernetes.
  
- ScaledObject
With --polling-interval, we can control the interval used by KEDA to check Azure Service Bus Queue for messages.

## Azure Resource Manager

- copyIndex
Notice that the name of each resource includes the copyIndex() function, which returns the current iteration in the loop. copyIndex() is zero-based.

- copy
By adding copy loop to the resources section of your template, you can dynamically set the number of resources to deploy. You also avoid having to repeat template syntax.

## Container registries

- "use multiple containers in the same container group" this not is possible in windows.  
  Solution is:  
  --is-linux  
  --deployment-container-image-name

## Rest

- storageservices
  - If you believe that a SAS has been compromised, then you should revoke the SAS. You can revoke a user delegation SAS either by **revoking the user delegation key,** or **by changing or removing RBAC role assignments** for the security principal used to create the SAS.

## Azure Monitor

- to ensure that dependency tracking works for calls to the third-party database, below two dependency telemetry properties should be use:
  - operation.Telemetry.Id
  - operation.Telemetry.Context.Operation.Id

- User can use metric telemetry to get different application metrics like: requestsPerSecond, requestsInQueue, and use these values to know when to [scale](https://docs.microsoft.com/en-us/azure/azure-monitor/app/data-model-metric-telemetry).

## Azure front door

- that file must be between 1 KB and 8 MB in size, inclusive. No need to purge all cached assets.

- No need to purge all cached assets.

## CDN

- Caching behavior settings:
  - For global and custom caching rules, you can specify the following Caching behavior settings:

    - Bypass cache: Do not cache and ignore origin-provided cache-directive headers.

    - Override: Ignore origin-provided cache duration; use the provided cache duration instead. This will not override cache-control: no-cache.

    - Set if missing: Honor origin-provided cache-directive headers, if they exist; otherwise, use the provided cache duration.

## pattern

- Publisher-Subscriber pattern : In Azure, consider using Service Bus, Event Hubs or Event Grid. Other technologies that can be used for pub/sub messaging include Redis, RabbitMQ, and Apache Kafka.

## Notification Hub

- Send a Windows Push Notification Service (WNS) native notification:
  - Content-Type : Set to application/json;charset=utf-8 or application/xml. If the notification type (X-WNS-Type) is wns/raw, set to application/octet-stream.
  - ServiceBusNotification-Format : Set to windows

## WebJob

- WebJob types
  - Continuous: Runs on all instances that the web app runs on. You can optionally restrict the WebJob to a single instance.
  - Triggered : Runs on a single instance that Azure selects for load balancing.

## Logic apps

- Developer will use Code View, Non Developer will use Designer

- To use your logic app's managed identity(AAD) in your function, you must set your function's authentication level to anonymous. Otherwise, your logic app throws a "BadRequest" error.

## Comparison

- Compare-messaging-services [Azure event vs message](https://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services)
  > Event Grid  - Reactive programming Event distribution (discrete) React to status changes  
    Event Hubs  - Big data pipeline Event streaming (series) Telemetry and distributed data streaming  
    Service Bus - High-value enterprise messaging Message Order processing and financial transactions  

- API Management and Azure Application Gateway
  
  - API management is a service that is used to publish, secure, transform, maintain, and monitor API’s. It has some security features to protect from certain types of attacks which I’m coming to back to in a bit.  
  Application Gateway provides much of the same functionality to publish, secure, transform and monitor web services.  
  Application Gateway also has some more functionality such as providing load balancing and more security features using its web application firewall. Both do behave like a reverse proxy, APIM provides a policy framework to manipulate requests both inbound and outbound, along with features such as rate limiting and conditional caching. While Application Gateway has more features in terms of rewriting and manipulating traffic on an HTTP protocol stack.
